{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"VGG-11.jpg\"\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Build VGG-16 model\n",
    "class Layer():\n",
    "    def forward(self, inputs):\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        pass\n",
    "\n",
    "    def get_out_shape(self):\n",
    "        pass\n",
    "\n",
    "    def init_weight(self):\n",
    "        pass\n",
    "\n",
    "class VGG11:\n",
    "    def __init__(self, layers: list[Layer] = []):\n",
    "        pre_layer = layers[0]\n",
    "        pre_layer.init_weight()\n",
    "        for layer in layers[1:]:\n",
    "            layer.input_shape = pre_layer.get_out_shape()\n",
    "            layer.init_weight()\n",
    "            pre_layer = layer\n",
    "        self.layers: list[Layer] = layers\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = X\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, out_grad, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            out_grad = layer.backward(out_grad, learning_rate)\n",
    "        return out_grad\n",
    "\n",
    "    def fit(self, X_train, Y_train, epochs=1, batch_size=32, learning_rate=0.001):\n",
    "        num_batch = (len(X_train)-1)//batch_size+1\n",
    "        for i_epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {i_epoch+1}/{epochs}:\")\n",
    "            train_loss = 0\n",
    "            acc = 0\n",
    "            progress = '.'*30\n",
    "            for i in range(num_batch-1):\n",
    "\n",
    "                batch_start = i * batch_size\n",
    "                batch_end = (i + 1) * batch_size\n",
    "                batch_X = X_train[batch_start: batch_end]\n",
    "                batch_Y = Y_train[batch_start: batch_end]\n",
    "                predictions = self.forward(batch_X)\n",
    "                out_grad = 2.0 * (predictions - batch_Y)\n",
    "                self.backward(out_grad, learning_rate)\n",
    "\n",
    "                # print result\n",
    "                acc_batch = np.mean(\n",
    "                    np.argmax(predictions, axis=1) == np.argmax(batch_Y, axis=1))\n",
    "                acc += acc_batch\n",
    "                loss = np.sum((predictions - batch_Y) ** 2)\n",
    "                train_loss += loss\n",
    "                i_str = int(i/num_batch*30)\n",
    "                progress = progress[:i_str] + \">\" + progress[i_str+1:]\n",
    "                print(\n",
    "                    f\"\\r {i}/{num_batch} [{progress}] accuaray: {acc_batch:.5f}, train loss = {loss/len(batch_Y):.5f}\", end='')\n",
    "                progress = progress[:i_str] + \"=\" + progress[i_str+1:]\n",
    "\n",
    "            train_loss /= len(X_train)\n",
    "\n",
    "            print(\n",
    "                f\"\\r {num_batch}/{num_batch} [{progress}] accuaray: {acc/num_batch:.5f}, train loss = {train_loss:.5f}\", end='')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def use_device(self, value):\n",
    "        for layer in self.layers:\n",
    "            output = layer.use_device = value\n",
    "\n",
    "class Flatten(Layer):\n",
    "    def __init__(self, input_shape=(28, 28, 1)):\n",
    "        self.input_shape = input_shape\n",
    "        pass\n",
    "\n",
    "    def get_out_shape(self):\n",
    "        t = 1\n",
    "        for i in self.input_shape:\n",
    "            t *= i\n",
    "        return t\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
    "        return inputs.reshape(inputs.shape[0], -1)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        shape = self.inputs.shape\n",
    "        return output_gradient.reshape(shape)\n",
    "\n",
    "    def init_weight(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(Layer):\n",
    "    def __init__(self, n_filters=32, filter_size=3, stride=1, activation=None, input_shape=(1, 32, 32), padding='valid'):\n",
    "        self.input_shape = input_shape\n",
    "        self.n_filters = n_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.activation = activation\n",
    "        self.padding = padding\n",
    "        self.bias = np.zeros((n_filters, 1))\n",
    "        self.init_weight()\n",
    "\n",
    "    def get_out_shape(self):\n",
    "        if self.padding == 'valid':\n",
    "            output_width = (self.input_shape[2] - self.filter_size) // self.stride + 1\n",
    "            output_height = (self.input_shape[1] - self.filter_size) // self.stride + 1\n",
    "        elif self.padding == 'same':\n",
    "            output_width = self.input_shape[2] // self.stride\n",
    "            output_height = self.input_shape[1] // self.stride\n",
    "        return (self.n_filters, output_height, output_width)\n",
    "    \n",
    "    def init_weight(self):\n",
    "            np.random.seed(10)\n",
    "            self.weights = np.random.randn(self.n_filters, self.input_shape[0],self.filter_size, self.filter_size)/(self.filter_size**2)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        n_batchs, n_channels, in_height, in_width = inputs.shape\n",
    "        print(inputs.shape)\n",
    "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
    "\n",
    "        output_height, output_width = self.get_out_shape()[1:]\n",
    "        outputs = np.zeros((n_batchs, self.n_filters, output_height, output_width))\n",
    "\n",
    "        # Pad inputs if needed\n",
    "        if self.padding == 'same':\n",
    "            pad_height = ((output_height - 1) * self.stride + self.filter_size - in_height) // 2\n",
    "            pad_width = ((output_width - 1) * self.stride + self.filter_size - in_width) // 2\n",
    "            inputs_padded = np.pad(inputs, ((0, 0), (0, 0), (pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "        else:\n",
    "            inputs_padded = inputs\n",
    "\n",
    "        # Convolution operation\n",
    "        for row in range(output_height):\n",
    "            for col in range(output_width):\n",
    "                for f_idx in range(self.n_filters):\n",
    "                    row_start = row * self.stride\n",
    "                    row_end = row_start + self.filter_size\n",
    "                    col_start = col * self.stride\n",
    "                    col_end = col_start + self.filter_size\n",
    "                    outputs[:, f_idx, row, col] = np.sum(self.weights[f_idx] * inputs_padded[:, :, row_start:row_end, col_start:col_end], axis=(1, 2, 3))\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            outputs = np.maximum(0, outputs)\n",
    "        print(outputs.shape)\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        n_batchs, input_channels, input_height, input_width = self.inputs.shape\n",
    "        _, n_filters, output_height, output_width = output_gradient.shape\n",
    "        filter_gradient = np.zeros(self.weights.shape)\n",
    "        \n",
    "        # Pad input_gradient if needed\n",
    "        if self.padding == 'same':\n",
    "            input_gradient = np.zeros(self.inputs.shape)\n",
    "            pad_height = ((output_height - 1) * self.stride + self.filter_size - input_height) // 2\n",
    "            pad_width = ((output_width - 1) * self.stride + self.filter_size - input_width) // 2\n",
    "            input_padded = np.pad(self.inputs, ((0, 0), (0, 0), (pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "            input_gradient_padded = np.pad(input_gradient, ((0, 0), (0, 0), (pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "        else:\n",
    "            input_gradient_padded = np.zeros(self.inputs.shape)\n",
    "            input_padded = self.inputs\n",
    "        \n",
    "            pad_height = ((output_height - 1) * self.stride + self.filter_size - input_height) // 2\n",
    "        \n",
    "        print(input_height, input_width, output_height, output_width)\n",
    "        # print(f'filter_gradient, input_gradient_padded, output_gradient, input_padded: {filter_gradient.shape, input_gradient_padded.shape, output_gradient.shape, input_padded.shape}')\n",
    "\n",
    "        # Backpropagation\n",
    "        for row in range(output_height):\n",
    "            for col in range(output_width):\n",
    "                for filterIdx in range(n_filters):\n",
    "                    row_start = row * self.stride\n",
    "                    row_end = row_start + self.filter_size\n",
    "                    col_start = col * self.stride\n",
    "                    col_end = col_start + self.filter_size\n",
    "\n",
    "                    # print(f'row_start, row_end, col_start, col_end: {row_start, row_end, col_start, col_end}')\n",
    "                    out_grad_val = output_gradient[:, filterIdx, row, col, np.newaxis, np.newaxis, np.newaxis]\n",
    "                    filter_gradient[filterIdx] += np.sum(input_padded[:, :, row_start:row_end, col_start:col_end] * out_grad_val, axis=0)\n",
    "                    input_gradient_padded[:, :, row_start:row_end, col_start:col_end] += self.weights[filterIdx] * out_grad_val\n",
    "                    # print(f'out_grad_val, filter_gradient, input_gradient_padded: {out_grad_val.shape, filter_gradient.shape, input_gradient_padded.shape}')\n",
    "\n",
    "        # Determine the indices to slice the array to remove padding\n",
    "        top = pad_height\n",
    "        bottom = output_height + pad_height\n",
    "        left = pad_width\n",
    "        right = output_width + pad_width\n",
    "        # Slice the padded array to remove padding\n",
    "        input_gradient_padded = input_gradient_padded[:, :, top:bottom, left:right]\n",
    "\n",
    "        # print(input_gradient_padded.shape)\n",
    "        if self.activation == \"relu\":\n",
    "            input_gradient_padded[self.inputs <= 0] = 0\n",
    "        # print(input_gradient_padded.shape)\n",
    "        self.weights -= learning_rate * filter_gradient / n_batchs\n",
    "        return input_gradient_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(3,32,32)\n",
    "inputs = np.random.randint(0,255,(32,*input_shape))/255\n",
    "conv = Convolution(n_filters = 32,\n",
    "                   filter_size = 3,\n",
    "                   stride = 1,\n",
    "                   padding = 'same',\n",
    "                   input_shape = input_shape)\n",
    "%time out_host = conv.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time in_grad_host=conv.backward(out_host, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time in_grad_host=conv.backward(out_host, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Maxpooling Layer\n",
    "\n",
    "class MaxPool2D(Layer):\n",
    "    def __init__(self, pool_size=2, stride=2, input_shape=(1,28, 28)):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.use_device = False\n",
    "        self.inputs = None\n",
    "        self.inputs_device = None\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def get_out_shape(self):\n",
    "        output_height = ( self.input_shape[1] - self.pool_size) // self.stride + 1\n",
    "        output_width = (self.input_shape[2] -  self.pool_size) // self.stride + 1\n",
    "        return (self.input_shape[0],output_height, output_width)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Save input\n",
    "        batch_size,num_channels, input_height, input_width = inputs.shape\n",
    "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
    "        self.inputs = inputs\n",
    "        (_,output_height, output_width) = self.get_out_shape()\n",
    "\n",
    "        outputs = np.zeros( (batch_size,num_channels, output_height, output_width))\n",
    "        for h in range(output_height):\n",
    "            for w in range(output_width):\n",
    "                h_start = h * self.stride\n",
    "                h_end = h_start + self.pool_size\n",
    "                w_start = w * self.stride\n",
    "                w_end = w_start + self.pool_size\n",
    "                outputs[:, :,h, w] = np.max( inputs[:, :, h_start:h_end, w_start:w_end], axis=(2, 3))\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        batch_size,num_channels, output_height, output_width = output_gradient.shape\n",
    "        input_gradient = np.zeros(self.inputs.shape)\n",
    "        for h in range(output_height):\n",
    "            for w in range(output_width):\n",
    "                h_start = h * self.stride\n",
    "                h_end = h_start + self.pool_size\n",
    "                w_start = w * self.stride\n",
    "                w_end = w_start + self.pool_size\n",
    "                input_slice = self.inputs[:, :, h_start:h_end, w_start:w_end]\n",
    "                max_vals = np.max(\n",
    "                    input_slice, axis=(2, 3), keepdims=True)\n",
    "                max_mask = (input_slice == max_vals)\n",
    "                input_gradient[:,:, h_start:h_end, w_start:w_end] += max_mask * output_gradient[:,:,  h, w,  np.newaxis, np.newaxis]\n",
    "        return input_gradient\n",
    "    def init_weight(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(32,200,200)\n",
    "inputs = np.random.randint(0,255,(64,*input_shape))/255\n",
    "maxp = MaxPool2D(2,2,input_shape=input_shape)\n",
    "%time out_host=maxp.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time in_grad_host=maxp.backward(out_host,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Dense Layer\n",
    "class Dense(Layer):\n",
    "    def __init__(self, num_outputs, activation=None, input_shape=100):\n",
    "        self.num_outputs = num_outputs\n",
    "        self.biases = np.zeros((1, num_outputs))\n",
    "        self.activation = activation\n",
    "        self.use_device = False\n",
    "        self.inputs = None\n",
    "        self.input_shape = input_shape\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        self.weights = np.random.randn(\n",
    "            self.input_shape, self.num_outputs) / self.num_outputs\n",
    "\n",
    "    def get_out_shape(self):\n",
    "        return self.num_outputs\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        assert self.input_shape == inputs.shape[-1], \"Input shape incorrect\"\n",
    "        outputs = np.dot(inputs, self.weights) + self.biases\n",
    "        if self.activation == \"softmax\":\n",
    "            outputs = self.softmax(outputs)\n",
    "        if(self.activation == \"relu\"):\n",
    "            outputs = np.maximum(0, outputs)\n",
    "        return outputs\n",
    "\n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x-np.max(x, axis=1, keepdims=True))\n",
    "        return e_x/e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        input_grad = np.dot(output_gradient, self.weights.T)\n",
    "        weights_gradient = np.dot(self.inputs.T, output_gradient)\n",
    "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.biases -= learning_rate * biases_gradient\n",
    "        return input_grad\n",
    "\n",
    "\n",
    "class Flatten(Layer):\n",
    "    def __init__(self, input_shape=(28, 28, 1)):\n",
    "        self.input_shape = input_shape\n",
    "        pass\n",
    "\n",
    "    def get_out_shape(self):\n",
    "        t = 1\n",
    "        for i in self.input_shape:\n",
    "            t *= i\n",
    "        return t\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
    "        return inputs.reshape(inputs.shape[0], -1)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        shape = self.inputs.shape\n",
    "        return output_gradient.reshape(shape)\n",
    "\n",
    "    def init_weight(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=np.random.randint(1,255, (256,10000))/255\n",
    "dense=Dense(1024, input_shape= 10000)\n",
    "%time out_host=dense.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = VGG11([\n",
    "    Convolution(n_filters=64, filter_size=3, stride=1,activation='relu', input_shape=(3,32,32), padding = 'same'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Convolution(n_filters=128, filter_size=3, stride=1,activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Convolution(n_filters=256, filter_size=3, stride=1,activation='relu', padding = 'same'),\n",
    "    Convolution(n_filters=256, filter_size=3, stride=1,activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Convolution(n_filters=512, filter_size=3, stride=1,activation='relu', padding = 'same'),\n",
    "    Convolution(n_filters=512, filter_size=3, stride=1,activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Convolution(n_filters=512, filter_size=3, stride=1,activation='relu', padding = 'same'),\n",
    "    Convolution(n_filters=512, filter_size=3, stride=1,activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (49000, 3, 32, 32)\n",
      "y_train: (49000, 10)\n",
      "x_validation: (1000, 3, 32, 32)\n",
      "y_validation: (1000,)\n",
      "x_test: (1000, 3, 32, 32)\n",
      "y_test: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "def single_batch_cifar10(file):\n",
    "    with open(file, 'rb') as f_single_batch:\n",
    "        d_single_batch = pickle.load(f_single_batch, encoding='latin1')  \n",
    "        x = d_single_batch['data']  \n",
    "        y = d_single_batch['labels']  \n",
    "        x = x.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype('float')  # (10000, 32, 32, 3)\n",
    "        y = np.array(y)\n",
    "        return x, y\n",
    "\n",
    "def whole_cifar10():\n",
    "    x_collect = []\n",
    "    y_collect = []\n",
    "    x, y = [], []\n",
    "    for k in range(1, 6):\n",
    "        filename = os.path.join('./dataset/cifar-10-batches-py', 'data_batch_' + str(k))\n",
    "        x, y = single_batch_cifar10(filename)\n",
    "        x_collect.append(x)\n",
    "        y_collect.append(y)\n",
    "    x_train = np.concatenate(x_collect)  # (50000, 32, 32, 3)\n",
    "    y_train = np.concatenate(y_collect)  # (50000,)\n",
    "    del x, y\n",
    "    filename = os.path.join('./dataset/cifar-10-batches-py', 'test_batch')\n",
    "    x_test, y_test = single_batch_cifar10(filename)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def pre_process_cifar10():\n",
    "    x_train, y_train, x_test, y_test = whole_cifar10()\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "\n",
    "    batch_mask = list(range(49000, 50000))\n",
    "    x_validation = x_train[batch_mask]  # (1000, 32, 32, 3)\n",
    "    y_validation = y_train[batch_mask]  # (1000,)\n",
    "    batch_mask = list(range(49000))\n",
    "    x_train = x_train[batch_mask]  # (49000, 32, 32, 3)\n",
    "    y_train = y_train[batch_mask]  # (49000,)\n",
    "    batch_mask = list(range(1000))\n",
    "    x_test = x_test[batch_mask]  # (1000, 32, 32, 3)\n",
    "    y_test = y_test[batch_mask]  # (1000,)\n",
    "    mean_image = np.mean(x_train, axis=0)  # numpy.ndarray (32, 32, 3)\n",
    "    std = np.std(x_train, axis=0)  # numpy.ndarray (32, 32, 3)\n",
    "    dictionary = {'mean_image': mean_image, 'std': std}\n",
    "    with open('./dataset/mean_and_std.pickle', 'wb') as f_mean_std:\n",
    "        pickle.dump(dictionary, f_mean_std)\n",
    "    x_train -= mean_image\n",
    "    x_validation -= mean_image\n",
    "    x_test -= mean_image\n",
    "    x_train /= std\n",
    "    x_validation /= std\n",
    "    x_test /= std\n",
    "    x_train = x_train.transpose(0, 3, 1, 2)  # (49000, 3, 32, 32)\n",
    "    x_test = x_test.transpose(0, 3, 1, 2)  # (1000, 3, 32, 32)\n",
    "    x_validation = x_validation.transpose(0, 3, 1, 2)  # (1000, 3, 32, 32)\n",
    "\n",
    "\n",
    "    train_y = np.zeros((len(y_train),10))\n",
    "    test_y = np.zeros((len(y_test),10))\n",
    "\n",
    "    for i in range (len(y_train)):\n",
    "        train_y[i,y_train[i]]=1\n",
    "    for i in range (len(y_test)):\n",
    "        test_y[i,y_test[i]]=1\n",
    "    \n",
    "    # Returning result as dictionary\n",
    "    d_processed = {'x_train': x_train, 'y_train': train_y,\n",
    "                   'x_validation': x_validation, 'y_validation': y_validation,\n",
    "                   'x_test': x_test, 'y_test': test_y}\n",
    "\n",
    "    # Returning dictionary\n",
    "    return d_processed\n",
    "\n",
    "\n",
    "# Preprocessing data\n",
    "data = pre_process_cifar10()\n",
    "for i, j in data.items():\n",
    "    print(i + ':', j.shape)\n",
    "\n",
    "# Saving loaded and preprocessed data into 'pickle' file\n",
    "with open('./dataset/data.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_1.fit(data['x_train'], data['y_train'], epochs=1, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcmus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
